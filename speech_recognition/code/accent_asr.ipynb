{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitpytorchconda30801943d9eb494db636e62bebf70903",
   "display_name": "Python 3.7.7 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchaudio\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###data load (pickle file)\n",
    "\n",
    "load_path='/home/skgudwn34/Accented_speech/speech_recognition/input_data/'\n",
    "\n",
    "train_set=load_path+'train_set'\n",
    "train_df=pd.read_pickle(train_set)\n",
    "\n",
    "val_set=load_path+'val_set'\n",
    "val_df=pd.read_pickle(val_set)\n",
    "\n",
    "test_set=load_path+'test_set'\n",
    "test_df=pd.read_pickle(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###commonvoice dataset\n",
    "\n",
    "class Common_voice(Dataset):\n",
    "    def __init__(self,dataframe):\n",
    "        self.dataframe=dataframe\n",
    "        self.len=len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self,idx) -> Tuple[str,str,str,int,Tensor]:\n",
    "        return (self.dataframe['File'].iloc[idx],self.dataframe['Accent'].iloc[idx],self.dataframe['Sentence'].iloc[idx],\n",
    "        self.dataframe['Sample_rate'].iloc[idx],self.dataframe['Waveform'].iloc[idx])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\ntrain_dataset=Common_voice(train_df)\\nval_dataset=Common_voice(val_df)\\ntest_dataset=Common_voice(test_df)\\n'"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "'''\n",
    "train_dataset=Common_voice(train_df)\n",
    "val_dataset=Common_voice(val_df)\n",
    "test_dataset=Common_voice(test_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for idx, data in enumerate(test_dataset): \n",
    "    #print(data)\n",
    "\n",
    "#print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###edit distance\n",
    "'''\n",
    "Levenshtein distance는 두 시퀀스 간의 차이를 측정하기위한 문자열 메트릭\n",
    "Levenshtein distance는 한 단어를 다른 단어로 변경하는 데 필요한 최소 한 문자 편집 (대체, 삽입 또는 삭제) 수로 정의\n",
    "'''\n",
    "\n",
    "def levenshtein_distance(ref,hyp):\n",
    "    \n",
    "    m=len(ref) #reference\n",
    "    n=len(hyp) #hypothesis\n",
    "\n",
    "    #special case\n",
    "    if ref==hyp:\n",
    "        return 0\n",
    "    if m==0:\n",
    "        return n\n",
    "    if n==0:\n",
    "        return m\n",
    "\n",
    "    if m<n:\n",
    "        ref,hyp=hyp,ref\n",
    "        m,n=n,m\n",
    "\n",
    "    #use 0 (min(m,n)) space\n",
    "    distance=np.zeors((2,n+1),dtype=np.int32)\n",
    "\n",
    "    #initialize distance matrix\n",
    "    for j in range(0,n+1):\n",
    "        distance[0][j]=j\n",
    "\n",
    "    #calculate levenshtein distance\n",
    "    for i in range(1,m+1):\n",
    "\n",
    "        prev_row_idx=(i-1)%2\n",
    "        cur_row_idx=i%2\n",
    "\n",
    "        distance[cur_row_idx][0]=i\n",
    "\n",
    "        for j in range(1,n+1):\n",
    "            if ref[i-1]==hyp[j-1]:\n",
    "                distance[cur_row_idx][j]=distance[prev_row_idx][j-1]\n",
    "            else:\n",
    "                s_num=distance[prev_row_idx][j-1]+1\n",
    "                i_num=distance[cur_row_idx][j-1]+1\n",
    "                d_num=distance[prev_cur_idx][j]+1\n",
    "\n",
    "                distance[cur_row_idx][j]=min(s_num,i_num,d_num)\n",
    "\n",
    "    return distance[m%2][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    if ignore_case==True:\n",
    "        reference=reference.upper()\n",
    "        hypothesis=hypothesis.upper()\n",
    "    \n",
    "    ref_words=reference.split(delimiter)\n",
    "    hyp_words=hypothesis.split(delimiter)\n",
    "\n",
    "    edit_distance=levenshtein_distance(ref_words,hyp_words)\n",
    "\n",
    "    return float(edit_distance), len(ref_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_errors(reference, hypothesis, ignore_case=False, delimiter=' ', remove_space=False):\n",
    "    if ignore_case==True:\n",
    "        reference=reference.upper()\n",
    "        hypothesis=hypothesis.upper()\n",
    "\n",
    "    join_char=' '\n",
    "\n",
    "    if remove_space==True:\n",
    "        join_char=''\n",
    "\n",
    "    reference=join_char.join(filter(None,reference.split(delimiter)))\n",
    "    hypothesis=join_char.join(filter(None,hypothesis.split(delimiter)))\n",
    "\n",
    "    edit_distance=levenshtein_distance(reference,hypothesis)\n",
    "\n",
    "    return float(edit_distance),len(reference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###word error rate\n",
    "'''\n",
    "WER = (Sw + Dw + Iw) / Nw\n",
    "\n",
    "Sw는 대체 된 단어의 수\n",
    "Dw는 삭제 된 단어의 수\n",
    "Iw는 삽입 된 단어의 수\n",
    "Nw는 참조의 단어 수\n",
    "'''\n",
    "\n",
    "def WER(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "\n",
    "    edit_distance,ref_len=word_errors(reference,hypothesis,ignore_case,delimiter)\n",
    "\n",
    "    if ref_len==0:\n",
    "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
    "\n",
    "    wer=float(edit_distance)/ref_len\n",
    "\n",
    "    return wer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###character error rate\n",
    "'''\n",
    "CER = (Sc + Dc + Ic) / Nc\n",
    "\n",
    "Sc는 대체 된 문자의 수\n",
    "Dc는 삭제 된 문자의 수\n",
    "Ic는 삽입 된 문자의 수\n",
    "Nc는 참조의 문자 수\n",
    "'''\n",
    "\n",
    "def CER(reference, hypothesis, ignore_case=False, delimiter=' ', remove_space=False):\n",
    "\n",
    "    edit_distance,ref_len=char_errors(reference,hypothesis,ignore_case,delimiter,remove_space)\n",
    "\n",
    "    if ref_len==0:\n",
    "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
    "\n",
    "    cer=float(edit_distance)/ref_len\n",
    "\n",
    "    return cer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The outputs of the network are the graphemes of each language. \n",
    "At each output time-step t, the RNN makes a prediction over characters.\n",
    "In English we have `t ∈ {a, b, c, . . . , z,space, apostrophe, blank}\n",
    "'''\n",
    "\n",
    "###maps characters to integers and vice versa\n",
    "\n",
    "class TextTransform:\n",
    "    def __init__(self):\n",
    "        char_map_str=\"\"\"\n",
    "        ' 0\n",
    "        <SPACE> 1\n",
    "        A 2\n",
    "        B 3\n",
    "        C 4\n",
    "        D 5\n",
    "        E 6\n",
    "        F 7\n",
    "        G 8\n",
    "        H 9\n",
    "        I 10\n",
    "        J 11\n",
    "        K 12\n",
    "        L 13\n",
    "        M 14\n",
    "        N 15\n",
    "        O 16\n",
    "        P 17\n",
    "        Q 18\n",
    "        R 19\n",
    "        S 20\n",
    "        T 21\n",
    "        U 22\n",
    "        V 23\n",
    "        W 24\n",
    "        X 25\n",
    "        Y 26\n",
    "        Z 27\n",
    "        \"\"\"\n",
    "\n",
    "        self.char_map={}\n",
    "        self.index_map={}\n",
    "\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch,index=line.split()\n",
    "            self.char_map[ch]=int(index)\n",
    "            self.index_map[int(index)]=ch\n",
    "        \n",
    "        self.index_map[1]=' '\n",
    "\n",
    "    #Use a character map and convert text to an integer sequence\n",
    "    def text_to_int(self,text):\n",
    "\n",
    "        int_sequence=[]\n",
    "\n",
    "        for c in text:\n",
    "            if c==' ':\n",
    "                ch=self.char_map['<SPACE>']\n",
    "            else:\n",
    "                ch=self.char_map[c]\n",
    "            \n",
    "            int_sequence.append(ch)\n",
    "        \n",
    "        return int_sequence\n",
    "\n",
    "    #Use a character map and convert integer labels to an text sequence\n",
    "    def int_to_text(self,labels):\n",
    "\n",
    "        string=[]\n",
    "\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "\n",
    "        return ''.join(string).replace('<SPACE>',' ')\n",
    "\n",
    "text_transform = TextTransform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###spec augmentation\n",
    "\n",
    "#for trainset\n",
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    ")\n",
    "\n",
    "#for testset\n",
    "test_audio_transforms = torchaudio.transforms.MelSpectrogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###data processing\n",
    "\n",
    "def data_processing(data,data_type):\n",
    "\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "\n",
    "    for (_, _, sentence, _, waveform) in data:\n",
    "        if data_type=='train':\n",
    "            spec=train_audio_transforms(waveform).squeeze(0).transpose(0,1)\n",
    "        elif data_type=='test':\n",
    "            spec=test_audio_transforms(waveform).squeeze(0).transpose(0,1)\n",
    "        else:\n",
    "            raise Exception('Data_type should be train or test')\n",
    "\n",
    "        spectrograms.append(spec)\n",
    "\n",
    "        label=torch.Tensor(text_transform.text_to_int(sentence.upper()))\n",
    "        labels.append(label)\n",
    "\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms=nn.utils.rnn.pad_sequence(spectrograms,batch_first=True).unsqueeze(1).transpose(2,3)\n",
    "    labels=nn.utils.rnn.pad_sequence(labels,batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Layer normalization built for cnns input\n",
    "\n",
    "class CNNLayerNorm(nn.Module):\n",
    "    def __init__(self,n_feats):\n",
    "        super(CNNLayerNorm,self).__init__()\n",
    "        self.layer_norm=nn.LayerNorm(n_feats)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x=x.transpose(2,3).contiguous() # (batch, channel, time, feature)\n",
    "        x=self.layer_norm(x)\n",
    "\n",
    "        return x.transpose(2,3).contiguous() # (batch, channel, feature, time) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Resnet\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel,stride,dropout,n_feats):\n",
    "        super(ResidualCNN,self).__init__()\n",
    "\n",
    "        self.cnn1=nn.Conv2d(in_channels,out_channels,kernel,stride,padding=kernel//2)\n",
    "        self.cnn2=nn.Conv2d(out_channels,out_channels,kernel,stride,padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self,x):\n",
    "        residual=x # (batch, channel, feature, time)\n",
    "        \n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        \n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        \n",
    "        x += residual\n",
    "\n",
    "        return x # (batch, channel, feature, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###BiGRU\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "    def __init__(self,rnn_dim,hidden_size,dropout,batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU=nn.GRU(input_size=rnn_dim,hidden_size=hidden_size,num_layers=1,batch_first=batch_first,bidirectional=True)\n",
    "        self.layer_norm=nn.LayerNorm(rnn_dim)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.layer_norm(x)\n",
    "        x=F.gelu(x)\n",
    "        x,_=self.BiGRU(x)\n",
    "        x=self.dropout(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ASR model\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel,self).__init__()\n",
    "        \n",
    "        n_feats=n_feats//2\n",
    "\n",
    "        self.cnn=nn.Conv2d(1,32,3,stride=stride,padding=1)\n",
    "\n",
    "        self.rescnn_layers=nn.Sequential(*[\n",
    "            ResidualCNN(32,32,kernel=3,stride=1,dropout=dropout,n_feats=n_feats) for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "\n",
    "        self.fully_connected=nn.Linear(n_feats*32,rnn_dim)\n",
    "\n",
    "        self.birnn_layers=nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,hidden_size=rnn_dim,dropout=dropout,batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2,rnn_dim),nn.GELU(),nn.Dropout(dropout),nn.Linear(rnn_dim,n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###decoder\n",
    "\n",
    "def GreedyDecoder(output,labels,label_lengths,blank_label=28,collapse_repeated=True):\n",
    "\n",
    "    arg_maxes=torch.argmax(output,dim=2)\n",
    "\n",
    "    decodes=[]\n",
    "    targets=[]\n",
    "\n",
    "    for i,args in enumerate(arg_maxes):\n",
    "        decode=[]\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j!=0 and index ==args[j-1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "            decodes.append(text_transform.int_to_text(decode))\n",
    "\n",
    "    return decodes, targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###keeps track of total iterations\n",
    "\n",
    "class IterMeter(object):\n",
    "    def __init__(self):\n",
    "        self.val=0\n",
    "\n",
    "    def step(self):\n",
    "        self.val+=1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###training\n",
    "\n",
    "def train(model,device,train_loader,criterion,optimizer,epoch,iter_meter):\n",
    "    print(\"Train start\")\n",
    "    model.train()\n",
    "\n",
    "    data_len=len(train_loader.dataset)\n",
    "\n",
    "    for batch_idx,data in enumerate(train_loader):\n",
    "        spectrograms,labels,input_lengths,label_lengths=data\n",
    "        spectrograms,labels=spectrograms.to(device),labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output=model(spectrograms)  # (batch, time, n_class)\n",
    "        output=F.log_softmax(output, dim=2)\n",
    "        output=output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "        loss=criterion(output,labels,input_lengths,label_lengths)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        iter_meter.step()\n",
    "\n",
    "        if batch_idx%100==0 or batch_idx==data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(spectrograms), data_len,100. * batch_idx / len(train_loader), loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,device,test_loader,criterion,epoch,iter_meter):\n",
    "    print(\"Test start\")\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss=0\n",
    "    test_cer,test_wer=[],[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            spectrograms,labels,input_lengths,label_lengths=data \n",
    "            spectrograms,labels=spectrograms.to(device),labels.to(device)\n",
    "\n",
    "            output=model(spectrograms) # (batch, time, n_class)\n",
    "            output=F.log_softmax(output, dim=2)\n",
    "            output=output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "            loss=criterion(output,labels,input_lengths,label_lengths)\n",
    "            test_loss+=loss.item()/len(test_loader)\n",
    "\n",
    "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "\n",
    "            for j in range(len(decoded_preds)):\n",
    "                test_cer.append(CER(decoded_targets[j], decoded_preds[j]))\n",
    "                test_wer.append(WER(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "    avg_cer=sum(test_cer)/len(test_cer)\n",
    "    avg_wer=sum(test_wer)/len(test_wer)\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Experiment\n",
    "\n",
    "def main(learning_rate, batch_size, epoch):\n",
    "\n",
    "    hparams = {\n",
    "        \"n_cnn_layers\": 3,\n",
    "        \"n_rnn_layers\": 5,\n",
    "        \"rnn_dim\": 512,\n",
    "        \"n_class\": 29,\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\":2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "    use_cuda=torch.cuda.is_available()\n",
    "    torch.manual_seed(7)\n",
    "    device=torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    train_dataset=Common_voice(train_df)\n",
    "    val_dataset=Common_voice(val_df)\n",
    "    test_dataset=Common_voice(test_df)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                **kwargs)\n",
    "\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'test'),\n",
    "                                **kwargs)\n",
    "\n",
    "    model = SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "        ).to(device)\n",
    "\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    optimizer=optim.Adam(model.parameters(),hparams['learning_rate'])\n",
    "    criterion=nn.CTCLoss(blank=28).to(device)\n",
    "\n",
    "    iter_meter=IterMeter()\n",
    "\n",
    "    for epoch in range(1,epoch+1):\n",
    "        train(model,device,train_loader,criterion,optimizer,epoch,iter_meter)\n",
    "        test(model,device,test_loader,criterion,epoch,iter_meter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Num Model Parameters 23705373\nTrain start\nTrain Epoch: 1 [0/15000 (0%)]\tLoss: 9.386733\n"
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/skgudwn34/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/skgudwn34/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"<ipython-input-22-dc3776c1896c>\", line 31, in <lambda>\n    collate_fn=lambda x: data_processing(x, 'train'),\n  File \"<ipython-input-13-aa93d92b6b8a>\", line 20, in data_processing\n    label=torch.Tensor(text_transform.text_to_int(sentence.upper()))\n  File \"<ipython-input-11-ccb786efec6d>\", line 61, in text_to_int\n    ch=self.char_map[c]\nKeyError: 'É'\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-bad9f63a6e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-dc3776c1896c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(learning_rate, batch_size, epoch)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter_meter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter_meter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-8dd76854909f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, criterion, optimizer, epoch, iter_meter)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mspectrograms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mspectrograms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspectrograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/skgudwn34/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/skgudwn34/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"<ipython-input-22-dc3776c1896c>\", line 31, in <lambda>\n    collate_fn=lambda x: data_processing(x, 'train'),\n  File \"<ipython-input-13-aa93d92b6b8a>\", line 20, in data_processing\n    label=torch.Tensor(text_transform.text_to_int(sentence.upper()))\n  File \"<ipython-input-11-ccb786efec6d>\", line 61, in text_to_int\n    ch=self.char_map[c]\nKeyError: 'É'\n"
     ]
    }
   ],
   "source": [
    "###start experiment\n",
    "learning_rate = 5e-4\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "main(learning_rate, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}